{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJnjQb9C7U-M"
      },
      "source": [
        "# Whatsapp Sentimemt Analysis\n",
        "## Proyecto Tópicos en Ciencias de la Computación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3BuNXLv7U-O"
      },
      "source": [
        "### Integrantes\n",
        "- Rodrigo Heiremans\n",
        "- Tomás Lagos\n",
        "- Nicolás Errázuriz\n",
        "\n",
        "### Librerías\n",
        "- python 3.8.10\n",
        "- numpy 1.20.3\n",
        "- nltk 3.7\n",
        "- lime 0.2.0.1\n",
        "- spacy 3.5.1\n",
        "- gcsfs 2023.3.0\n",
        "- protobuf 3.20.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización NLTK Sentiment Analysis"
      ],
      "metadata": {
        "id": "JE6bZ8ShZkiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install python-dev #hunspell\n",
        "!apt-get install libhunspell-dev #hunspell"
      ],
      "metadata": {
        "id": "QOJr0_qOUREu",
        "outputId": "3bd5fb33-a8ff-4396-a160-de4de66d7f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,408 kB]\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,344 kB]\n",
            "Fetched 7,288 kB in 3s (2,622 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'python-dev-is-python2' instead of 'python-dev'\n",
            "The following additional packages will be installed:\n",
            "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
            "  python-is-python2 python2 python2-dev python2-minimal python2.7-dev\n",
            "Suggested packages:\n",
            "  python2-doc python-tk\n",
            "The following NEW packages will be installed:\n",
            "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
            "  python-dev-is-python2 python-is-python2 python2 python2-dev python2-minimal\n",
            "  python2.7-dev\n",
            "0 upgraded, 10 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 3,870 kB of archives.\n",
            "After this operation, 18.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7 amd64 2.7.18-1~20.04.3 [1,037 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-dev amd64 2.7.18-1~20.04.3 [2,466 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-dev amd64 2.7.17-2ubuntu4 [7,140 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-is-python2 all 2.7.17-4 [2,496 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7-dev amd64 2.7.18-1~20.04.3 [293 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-dev amd64 2.7.17-2ubuntu4 [1,268 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-dev-is-python2 all 2.7.17-4 [1,396 B]\n",
            "Fetched 3,870 kB in 1s (3,990 kB/s)\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 122560 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2.7:amd64.\n",
            "Preparing to unpack .../1-libpython2.7_2.7.18-1~20.04.3_amd64.deb ...\n",
            "Unpacking libpython2.7:amd64 (2.7.18-1~20.04.3) ...\n",
            "Selecting previously unselected package libpython2.7-dev:amd64.\n",
            "Preparing to unpack .../2-libpython2.7-dev_2.7.18-1~20.04.3_amd64.deb ...\n",
            "Unpacking libpython2.7-dev:amd64 (2.7.18-1~20.04.3) ...\n",
            "Selecting previously unselected package libpython2-dev:amd64.\n",
            "Preparing to unpack .../3-libpython2-dev_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-dev:amd64 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python-is-python2.\n",
            "Preparing to unpack .../4-python-is-python2_2.7.17-4_all.deb ...\n",
            "Unpacking python-is-python2 (2.7.17-4) ...\n",
            "Selecting previously unselected package python2.7-dev.\n",
            "Preparing to unpack .../5-python2.7-dev_2.7.18-1~20.04.3_amd64.deb ...\n",
            "Unpacking python2.7-dev (2.7.18-1~20.04.3) ...\n",
            "Selecting previously unselected package python2-dev.\n",
            "Preparing to unpack .../6-python2-dev_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-dev (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python-dev-is-python2.\n",
            "Preparing to unpack .../7-python-dev-is-python2_2.7.17-4_all.deb ...\n",
            "Unpacking python-dev-is-python2 (2.7.17-4) ...\n",
            "Setting up libpython2.7:amd64 (2.7.18-1~20.04.3) ...\n",
            "Setting up libpython2.7-dev:amd64 (2.7.18-1~20.04.3) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up libpython2-dev:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python-is-python2 (2.7.17-4) ...\n",
            "Setting up python2.7-dev (2.7.18-1~20.04.3) ...\n",
            "Setting up python2-dev (2.7.17-2ubuntu4) ...\n",
            "Setting up python-dev-is-python2 (2.7.17-4) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dictionaries-common emacsen-common hunspell-en-us libhunspell-1.7-0\n",
            "  libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  ispell | aspell | hunspell wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core\n",
            "The following NEW packages will be installed:\n",
            "  dictionaries-common emacsen-common hunspell-en-us libhunspell-1.7-0\n",
            "  libhunspell-dev libtext-iconv-perl\n",
            "0 upgraded, 6 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 721 kB of archives.\n",
            "After this operation, 2,924 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libtext-iconv-perl amd64 1.7-7 [13.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 emacsen-common all 3.0.4 [14.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 dictionaries-common all 1.28.1 [178 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 hunspell-en-us all 1:2018.04.16-1 [170 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libhunspell-1.7-0 amd64 1.7.0-2build2 [147 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libhunspell-dev amd64 1.7.0-2build2 [197 kB]\n",
            "Fetched 721 kB in 1s (1,117 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 122736 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-7_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-7) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../1-emacsen-common_3.0.4_all.deb ...\n",
            "Unpacking emacsen-common (3.0.4) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../2-dictionaries-common_1.28.1_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.28.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../3-hunspell-en-us_1%3a2018.04.16-1_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2018.04.16-1) ...\n",
            "Selecting previously unselected package libhunspell-1.7-0:amd64.\n",
            "Preparing to unpack .../4-libhunspell-1.7-0_1.7.0-2build2_amd64.deb ...\n",
            "Unpacking libhunspell-1.7-0:amd64 (1.7.0-2build2) ...\n",
            "Selecting previously unselected package libhunspell-dev:amd64.\n",
            "Preparing to unpack .../5-libhunspell-dev_1.7.0-2build2_amd64.deb ...\n",
            "Unpacking libhunspell-dev:amd64 (1.7.0-2build2) ...\n",
            "Setting up libtext-iconv-perl (1.7-7) ...\n",
            "Setting up emacsen-common (3.0.4) ...\n",
            "Setting up libhunspell-1.7-0:amd64 (1.7.0-2build2) ...\n",
            "Setting up libhunspell-dev:amd64 (1.7.0-2build2) ...\n",
            "Setting up dictionaries-common (1.28.1) ...\n",
            "Setting up hunspell-en-us (1:2018.04.16-1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for dictionaries-common (1.28.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hunspell"
      ],
      "metadata": {
        "id": "xVd82AHhUl2c",
        "outputId": "3cfccba8-98d2-4058-cbd2-eb30c8a6015c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hunspell\n",
            "  Downloading hunspell-0.5.5.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hunspell\n",
            "  Building wheel for hunspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hunspell: filename=hunspell-0.5.5-cp310-cp310-linux_x86_64.whl size=71758 sha256=7be4df0edf13a3afdc6737b1c96369f2d4583e86f103f4b42e8c800d4cf51782\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/f3/bd/bdce223532ee8aa5345e14e0d6e7ba06cbbaff8767cefe1ec8\n",
            "Successfully built hunspell\n",
            "Installing collected packages: hunspell\n",
            "Successfully installed hunspell-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/wooorm/dictionaries/master/dictionaries/es-MX/index.aff\n",
        "!wget https://raw.githubusercontent.com/wooorm/dictionaries/master/dictionaries/es-MX/index.dic\n",
        "!mv /content/index.aff /content/es_CL.aff\n",
        "!mv /content/index.dic /content/es_CL.dic"
      ],
      "metadata": {
        "id": "i0eOHC0iUnXC",
        "outputId": "f31497a8-927b-4f59-fdae-ee6609aa99a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-22 16:45:30--  https://raw.githubusercontent.com/wooorm/dictionaries/master/dictionaries/es-MX/index.aff\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 158014 (154K) [text/plain]\n",
            "Saving to: ‘index.aff’\n",
            "\n",
            "\rindex.aff             0%[                    ]       0  --.-KB/s               \rindex.aff           100%[===================>] 154.31K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-05-22 16:45:30 (55.4 MB/s) - ‘index.aff’ saved [158014/158014]\n",
            "\n",
            "--2023-05-22 16:45:30--  https://raw.githubusercontent.com/wooorm/dictionaries/master/dictionaries/es-MX/index.dic\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 710101 (693K) [text/plain]\n",
            "Saving to: ‘index.dic’\n",
            "\n",
            "index.dic           100%[===================>] 693.46K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-05-22 16:45:30 (69.9 MB/s) - ‘index.dic’ saved [710101/710101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon') # Obligatorio para usar SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "import hunspell # Nos ayudará con los diccionarios en español\n",
        "# Buscar diccionarios en carpeta de instalacion\n",
        "# Más diccionarios de idiomas disponibles en: https://github.com/wooorm/dictionaries/tree/master/dictionaries\n",
        "diccionario = hunspell.HunSpell('/content/es_CL.dic','/content/es_CL.aff')\n",
        "\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "sA83qxpsUqcb",
        "outputId": "e2295398-8e81-4472-8dfe-d5d7136fde63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corregir_palabras(corrector, palabras, agregarPrimero=[]):   \n",
        "    #codificacion = corrector.get_dic_encoding()   # obtenemos la codificacion para usarla luego\n",
        "\n",
        "    # agregamos las palabras aleatorias al diccionario\n",
        "    for palabra in agregarPrimero:\n",
        "        corrector.add(palabra)\n",
        "\n",
        "    # autocorreccion de palabras\n",
        "    corregida = []\n",
        "    for p in palabras:\n",
        "        ok = corrector.spell(p)   # verificamos ortografia\n",
        "        if not ok:\n",
        "            sugerencias = corrector.suggest(p)\n",
        "            if len(sugerencias) > 0:  # hay sugerencias\n",
        "                # tomamos la  mejor sugerencia(decodificada a string)\n",
        "                mejor_sugerencia = sugerencias[0]   \n",
        "                corregida.append(mejor_sugerencia)\n",
        "            else:\n",
        "                corregida.append(p)  # no hay ninguna sugerecia para la palabra\n",
        "        else:\n",
        "            corregida.append(p)   # esta palabra esta corregida\n",
        "\n",
        "    return corregida\n",
        "\n",
        "\n",
        "def corregir_oracion(corrector,string):\n",
        "    oracion_fixed=''\n",
        "    if len(string)>0:\n",
        "        oracion_dirty=string.split()\n",
        "        oracion_fixed=corregir_palabras(corrector, oracion_dirty,[''])\n",
        "        oracion_fixed=' '.join(oracion_fixed)\n",
        "    else:\n",
        "      print('error')\n",
        "    return oracion_fixed"
      ],
      "metadata": {
        "id": "VecffouKU1N3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ReviewText):\n",
        "    ReviewText = ReviewText.str.replace('\\t', ' ')\n",
        "    ReviewText = ReviewText.str.replace('\\r', ' ')\n",
        "    ReviewText = ReviewText.str.replace('\\n', ' ')\n",
        "    return (ReviewText)    "
      ],
      "metadata": {
        "id": "st-qUNbuU48V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_polarity():\n",
        "  for i in range(len(df)):#len(df)\n",
        "      try:\n",
        "          temp=df['RelatoFixedTranslated'][i]    \n",
        "          # translation= translate_client.translate(temp,target_language='en',source_language='es') # Already translated\n",
        "          # translation=translation['translatedText'] # Already translated\n",
        "          p=sid.polarity_scores(str(temp))['compound']\n",
        "          neg=sid.polarity_scores(str(temp))['neg']\n",
        "          neu=sid.polarity_scores(str(temp))['neu']\n",
        "          pos=sid.polarity_scores(str(temp))['pos']\n",
        "          df.loc[i,'polarity']=p\n",
        "          df.loc[i,'neg']=neg\n",
        "          df.loc[i,'neu']=neu\n",
        "          df.loc[i,'pos']=pos\n",
        "          #df.loc[i,'translated']=str(translation) # Already translated\n",
        "          print(i,end=' - ')\n",
        "          #sleep(0.1+random.random()/2) # Already translated\n",
        "      except Exception as e:\n",
        "          print('Error {}:{}'.format(i,e))"
      ],
      "metadata": {
        "id": "u4phZKxPU_0_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_checker_spanish():\n",
        "    try:\n",
        "        df.drop('Código', axis=1, inplace=True) # No viene al caso\n",
        "        df.drop('Nombre', axis=1, inplace=True) # Anonimos\n",
        "        df.drop('Número', axis=1, inplace=True) # No viene al caso\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    df['polarity']=0\n",
        "    df['neg']=0\n",
        "    df['neu']=0\n",
        "    df['pos']=0\n",
        "    df['translated']=0\n",
        "\n",
        "    for i in range(len(df)):#len(df)\n",
        "        try:\n",
        "            temp=df['Relato'][i]\n",
        "            fixed=corregir_oracion(diccionario,temp)\n",
        "            #fixed=preprocess(str(fixed))\n",
        "            df.loc[i,'RelatoFixed']=fixed\n",
        "            print(i,end=' - ')\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Error {}:{}'.format(i,e))"
      ],
      "metadata": {
        "id": "TL2s-hxSVfjG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparación de DATA"
      ],
      "metadata": {
        "id": "jWivkPyFZt1y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43Ilmfp3Zz9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código de Clases desde aquí"
      ],
      "metadata": {
        "id": "X3rTA5V0VARD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvP3z3-y7U-P"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import product_reviews_1\n",
        "camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
        "\n",
        "reviews = []\n",
        "\n",
        "for review in camera_reviews:\n",
        "    sentences = []\n",
        "    for sentence in review.sents():\n",
        "        text = \" \".join(sentence)\n",
        "        sentences.append(text)\n",
        "    document = \" \".join(sentences)\n",
        "    reviews.append(document)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQbI37qn7U-Q"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Load stop-words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Initialize tokenizer\n",
        "# It's also possible to try with a stemmer or to mix a stemmer and a lemmatizer\n",
        "tokenizer = RegexpTokenizer('[\\'a-zA-Z]+')\n",
        "\n",
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize(document):\n",
        "    words = []\n",
        "\n",
        "    for sentence in sent_tokenize(document):\n",
        "        tokens = [lemmatizer.lemmatize(t.lower()) for t in tokenizer.tokenize(sentence) if t.lower() not in stop_words and len(t) > 2]\n",
        "        words += tokens\n",
        "    \n",
        "    text = ' '.join(words)\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzVMujl27U-Q"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "\n",
        "for review in reviews:\n",
        "    document = tokenize(review)\n",
        "    corpus.append(document)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oBg1tUE7U-Q",
        "outputId": "00c46215-36d7-4b52-8cfa-36706de17e92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IqYbxgD7U-R"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Create an instance of SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer() # compound in [-1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-zBuWqD7U-R"
      },
      "source": [
        "Ver documentación de vader en: https://www.nltk.org/api/nltk.sentiment.vader.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAKTiUdN7U-R"
      },
      "outputs": [],
      "source": [
        "label = []\n",
        "for i in range(len(corpus)):\n",
        "    if analyzer.polarity_scores(corpus[i])['compound'] > 0.2: \n",
        "        label.append('Positive') # positive sentiment\n",
        "    elif analyzer.polarity_scores(corpus[i])['compound'] < -0.2:\n",
        "        label.append('Negative') # negative sentiment\n",
        "    else:\n",
        "        label.append('Neutral') # neutral sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v-TTizm7U-R",
        "outputId": "b0670459-cc79-496a-8d71-9c065bc59581"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>polarities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recently purchased canon powershot extremely s...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yep first digital camera toy software engineer...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>extensive research comparing different megapix...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bought canon month ago say satisfied taken hun...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>camera one full day say wonderful photo qualit...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>positive slr like programming exposure control...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>camera wonderful set feature lcd screen pull r...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>recent price drop made best bargain digital ca...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>recommend unreservedly powershot potential buy...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>else say camera work make photograph work want...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>great camera canon give ton control photo buff...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>first digital camera pleased know whole lot ph...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>received camera two day ago already love featu...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>camera significantly noise iso nikon</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bought camera day ago get used first feeling p...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bought last week amazon got great deal reputab...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>maybe lack experience found shot camera disapp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>long time user highly responsive film slrs pro...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>month pleased decision perfect camera photo ho...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>reading positive review camera leading consume...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>great fan set somewhat negative expectation di...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>love thought would upgrade big mistake problem...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>shopping digital camera looked nikon olympus n...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>powershot great camera help photographer take ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>catch canon camera perhaps digital camera unre...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>first digital camera could happier plan sellin...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>canon perhaps best camera tried sony carl zeis...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>used canon powershot year loved flaw learned d...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>looking buy digital camera long time finally d...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>read review spec performance opinion perfectly...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>first digital camera pleased far wanted someth...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>best camera ever image quality color function ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>write many review compelled camera first forem...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>spent lot time comparing different camera real...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>owned camera short time would give anything su...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>bought product month ago used variety situatio...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>far finest camera price category ever used als...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>camera closest perfect digicam megapixel beat ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>camera work art science understood take great ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>see rank product since merchant amazon collabo...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>camera major design flaw look viewfinder lcd b...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>using powershot nearly year wanted upgrade meg...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>using six week proven advertised hand comparis...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>canon improves almost way fact beat nikon cool...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>definetely great camera proven canon built qua...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               review polarities\n",
              "0   recently purchased canon powershot extremely s...   Positive\n",
              "1   yep first digital camera toy software engineer...   Positive\n",
              "2   extensive research comparing different megapix...   Positive\n",
              "3   bought canon month ago say satisfied taken hun...   Positive\n",
              "4   camera one full day say wonderful photo qualit...   Positive\n",
              "5   positive slr like programming exposure control...   Positive\n",
              "6   camera wonderful set feature lcd screen pull r...   Positive\n",
              "7   recent price drop made best bargain digital ca...   Positive\n",
              "8   recommend unreservedly powershot potential buy...   Positive\n",
              "9   else say camera work make photograph work want...   Positive\n",
              "10  great camera canon give ton control photo buff...   Positive\n",
              "11  first digital camera pleased know whole lot ph...   Positive\n",
              "12  received camera two day ago already love featu...   Positive\n",
              "13               camera significantly noise iso nikon    Neutral\n",
              "14  bought camera day ago get used first feeling p...   Positive\n",
              "15  bought last week amazon got great deal reputab...   Positive\n",
              "16  maybe lack experience found shot camera disapp...   Positive\n",
              "17  long time user highly responsive film slrs pro...   Positive\n",
              "18  month pleased decision perfect camera photo ho...   Positive\n",
              "19  reading positive review camera leading consume...   Positive\n",
              "20  great fan set somewhat negative expectation di...   Positive\n",
              "21  love thought would upgrade big mistake problem...   Negative\n",
              "22  shopping digital camera looked nikon olympus n...   Positive\n",
              "23  powershot great camera help photographer take ...   Positive\n",
              "24  catch canon camera perhaps digital camera unre...   Positive\n",
              "25  first digital camera could happier plan sellin...   Positive\n",
              "26  canon perhaps best camera tried sony carl zeis...   Positive\n",
              "27  used canon powershot year loved flaw learned d...   Positive\n",
              "28  looking buy digital camera long time finally d...   Positive\n",
              "29  read review spec performance opinion perfectly...   Positive\n",
              "30  first digital camera pleased far wanted someth...   Positive\n",
              "31  best camera ever image quality color function ...   Positive\n",
              "32  write many review compelled camera first forem...   Positive\n",
              "33  spent lot time comparing different camera real...   Positive\n",
              "34  owned camera short time would give anything su...   Positive\n",
              "35  bought product month ago used variety situatio...   Positive\n",
              "36  far finest camera price category ever used als...   Positive\n",
              "37  camera closest perfect digicam megapixel beat ...   Positive\n",
              "38  camera work art science understood take great ...   Positive\n",
              "39  see rank product since merchant amazon collabo...   Positive\n",
              "40  camera major design flaw look viewfinder lcd b...   Negative\n",
              "41  using powershot nearly year wanted upgrade meg...   Positive\n",
              "42  using six week proven advertised hand comparis...   Positive\n",
              "43  canon improves almost way fact beat nikon cool...   Positive\n",
              "44  definetely great camera proven canon built qua...   Positive"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(corpus, columns = ['review'])\n",
        "df['polarities'] = label\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqhBqoD7U-S"
      },
      "source": [
        "# Supervised sentiment analysis (training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUHxnvyX7U-S",
        "outputId": "ded71cd9-d697-4216-df99-1d0578683edb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-78044fd3cd00>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  data = pd.read_csv('gs://nlp_amazon_data/train.ft.txt', sep=\"__label__\", header = None)\n"
          ]
        }
      ],
      "source": [
        "# load in dataset and separate by the __label__ classifier in the text file\n",
        "data = pd.read_csv('gs://nlp_amazon_data/train.ft.txt', sep=\"__label__\", header = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc7x7QBl7U-S",
        "outputId": "e7307422-0469-4dab-a12c-1f1f287ee34e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599995</th>\n",
              "      <td>Don't do it!!: The high chair looks great when...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599996</th>\n",
              "      <td>Looks nice, low functionality: I have used thi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599997</th>\n",
              "      <td>compact, but hard to clean: We have a small ho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599998</th>\n",
              "      <td>what is it saying?: not sure what this book is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599999</th>\n",
              "      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3600000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    review sentiment\n",
              "0        Stuning even for the non-gamer: This sound tra...         2\n",
              "1        The best soundtrack ever to anything.: I'm rea...         2\n",
              "2        Amazing!: This soundtrack is my favorite music...         2\n",
              "3        Excellent Soundtrack: I truly like this soundt...         2\n",
              "4        Remember, Pull Your Jaw Off The Floor After He...         2\n",
              "...                                                    ...       ...\n",
              "3599995  Don't do it!!: The high chair looks great when...         1\n",
              "3599996  Looks nice, low functionality: I have used thi...         1\n",
              "3599997  compact, but hard to clean: We have a small ho...         1\n",
              "3599998  what is it saying?: not sure what this book is...         1\n",
              "3599999  Makes My Blood Run Red-White-And-Blue: I agree...         2\n",
              "\n",
              "[3600000 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.drop(0, inplace=True, axis=1)\n",
        "data['sentiment'] = data[1].str[0]\n",
        "data[1] = data[1].str[2:]\n",
        "data = data.rename(columns={1: 'review'})\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvPXb5ku7U-S"
      },
      "outputs": [],
      "source": [
        "sample = data.sample(n=100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSxOkvDL7U-S"
      },
      "source": [
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_BtZt4P7U-S",
        "outputId": "ae4e4cc9-df9c-4045-8f5e-2ad2b1d384ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1669564</th>\n",
              "      <td>Awesome!: These are Great! Bought these for my...</td>\n",
              "      <td>2</td>\n",
              "      <td>awesome great bought daughter boyfriend loves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3314648</th>\n",
              "      <td>Shame on you Lewin!: Corrupting the integrity ...</td>\n",
              "      <td>1</td>\n",
              "      <td>shame lewin corrupting integrity amazon review...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226503</th>\n",
              "      <td>ultimate christmas c d volumn 3: here we go ag...</td>\n",
              "      <td>2</td>\n",
              "      <td>ultimate christmas volumn great christmas favo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709998</th>\n",
              "      <td>Stand has a major defect: I bought this monito...</td>\n",
              "      <td>1</td>\n",
              "      <td>stand major defect bought monitor months ago s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360808</th>\n",
              "      <td>Track After Track, On Repeat, Delicious to the...</td>\n",
              "      <td>2</td>\n",
              "      <td>track track repeat delicious ears feet lies li...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    review sentiment  \\\n",
              "1669564  Awesome!: These are Great! Bought these for my...         2   \n",
              "3314648  Shame on you Lewin!: Corrupting the integrity ...         1   \n",
              "1226503  ultimate christmas c d volumn 3: here we go ag...         2   \n",
              "709998   Stand has a major defect: I bought this monito...         1   \n",
              "360808   Track After Track, On Repeat, Delicious to the...         2   \n",
              "\n",
              "                                                text_clean  \n",
              "1669564  awesome great bought daughter boyfriend loves ...  \n",
              "3314648  shame lewin corrupting integrity amazon review...  \n",
              "1226503  ultimate christmas volumn great christmas favo...  \n",
              "709998   stand major defect bought monitor months ago s...  \n",
              "360808   track track repeat delicious ears feet lies li...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "import re\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.blank(\"en\") # Create a blank pipeline of a given language class\n",
        "REGX_USERNAME = r\"@[A-Za-z0-9$-_@.&+]+\"\n",
        "\n",
        "def preprocessing(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(REGX_USERNAME, ' ', text)\n",
        "  tokens = [token.text for token in nlp(text)]\n",
        "  tokens = [t for t in tokens if t not in STOP_WORDS and t not in string.punctuation and len(t) > 2]\n",
        "  tokens = [t for t in tokens if not t.isdigit()]\n",
        "\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "sample[\"text_clean\"] = sample[\"review\"].apply(preprocessing)\n",
        "sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPUhkhzr7U-T",
        "outputId": "351ef3ea-681a-4411-cee2-53313fc4590b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1669564</th>\n",
              "      <td>Awesome!: These are Great! Bought these for my...</td>\n",
              "      <td>2</td>\n",
              "      <td>awesome great bought daughter boyfriend loves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3314648</th>\n",
              "      <td>Shame on you Lewin!: Corrupting the integrity ...</td>\n",
              "      <td>1</td>\n",
              "      <td>shame lewin corrupting integrity amazon review...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226503</th>\n",
              "      <td>ultimate christmas c d volumn 3: here we go ag...</td>\n",
              "      <td>2</td>\n",
              "      <td>ultimate christmas volumn great christmas favo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709998</th>\n",
              "      <td>Stand has a major defect: I bought this monito...</td>\n",
              "      <td>1</td>\n",
              "      <td>stand major defect bought monitor months ago s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360808</th>\n",
              "      <td>Track After Track, On Repeat, Delicious to the...</td>\n",
              "      <td>2</td>\n",
              "      <td>track track repeat delicious ears feet lies li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1765260</th>\n",
              "      <td>Not Recommended: Many of the recipes in this b...</td>\n",
              "      <td>1</td>\n",
              "      <td>recommended recipes book include ingredients b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2508426</th>\n",
              "      <td>Their Greatest!: This is George Michael/Wham's...</td>\n",
              "      <td>2</td>\n",
              "      <td>greatest george michael wham greatest album tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3098618</th>\n",
              "      <td>Cadburys Flake Case of 24: Very good product. ...</td>\n",
              "      <td>2</td>\n",
              "      <td>cadburys flake case good product family loves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1203438</th>\n",
              "      <td>Can server the purpose: I bought two of these ...</td>\n",
              "      <td>1</td>\n",
              "      <td>server purpose bought items small work suggest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1794850</th>\n",
              "      <td>HORRIBLE, AWFUL, DISAPPOINTING, RIDICULOUS!: T...</td>\n",
              "      <td>1</td>\n",
              "      <td>horrible awful disappointing ridiculous prosal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    review sentiment  \\\n",
              "1669564  Awesome!: These are Great! Bought these for my...         2   \n",
              "3314648  Shame on you Lewin!: Corrupting the integrity ...         1   \n",
              "1226503  ultimate christmas c d volumn 3: here we go ag...         2   \n",
              "709998   Stand has a major defect: I bought this monito...         1   \n",
              "360808   Track After Track, On Repeat, Delicious to the...         2   \n",
              "...                                                    ...       ...   \n",
              "1765260  Not Recommended: Many of the recipes in this b...         1   \n",
              "2508426  Their Greatest!: This is George Michael/Wham's...         2   \n",
              "3098618  Cadburys Flake Case of 24: Very good product. ...         2   \n",
              "1203438  Can server the purpose: I bought two of these ...         1   \n",
              "1794850  HORRIBLE, AWFUL, DISAPPOINTING, RIDICULOUS!: T...         1   \n",
              "\n",
              "                                                text_clean  \n",
              "1669564  awesome great bought daughter boyfriend loves ...  \n",
              "3314648  shame lewin corrupting integrity amazon review...  \n",
              "1226503  ultimate christmas volumn great christmas favo...  \n",
              "709998   stand major defect bought monitor months ago s...  \n",
              "360808   track track repeat delicious ears feet lies li...  \n",
              "...                                                    ...  \n",
              "1765260  recommended recipes book include ingredients b...  \n",
              "2508426  greatest george michael wham greatest album tr...  \n",
              "3098618  cadburys flake case good product family loves ...  \n",
              "1203438  server purpose bought items small work suggest...  \n",
              "1794850  horrible awful disappointing ridiculous prosal...  \n",
              "\n",
              "[100000 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNGT1-o97U-T"
      },
      "outputs": [],
      "source": [
        "dataset = list(sample[[\"text_clean\", \"sentiment\"]].sample(frac=1).itertuples(index=False, name=None))\n",
        "train_data = dataset[:75000]  # 75%\n",
        "dev_data = dataset[75000:90000] # 15%\n",
        "test_data = dataset[90000:] # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP0fqJym7U-T"
      },
      "outputs": [],
      "source": [
        "def convert(data, outfile):\n",
        "    db = spacy.tokens.DocBin()\n",
        "    docs = []\n",
        "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
        "        doc.cats[\"POS\"] = label == '2'\n",
        "        doc.cats[\"NEG\"] = label == '1'\n",
        "        db.add(doc)\n",
        "    \n",
        "    db.to_disk(outfile)\n",
        "convert(train_data, \"./train.spacy\")\n",
        "convert(dev_data, \"./dev.spacy\")\n",
        "convert(test_data, \"./test.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXJsXu-d7U-T",
        "outputId": "b7b54c93-3206-4968-870b-467ebfcc9cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-16 14:29:55.174794: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-03-16 14:29:55.690500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:55.690563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:55.690573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-16 14:29:56.644307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:56.644367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:56.645865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:56.645923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:56.645960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:56.645968: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: textcat\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy init config --lang en --pipeline textcat --optimize efficiency --force config.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ibkt_b87U-T"
      },
      "source": [
        "Ver documentación de config en: https://spacy.io/usage/training#quickstart\n",
        "\n",
        "Ver documentación de architectures en: https://spacy.io/api/architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKcsRTZR7U-T",
        "outputId": "7057b27a-a7ba-4065-cfcc-136a2c99dbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-16 14:29:59.199420: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-03-16 14:29:59.711462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:59.711518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:29:59.711524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-16 14:30:00.632075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:30:00.632133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:30:00.633629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:30:00.633671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:30:00.633701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:30:00.633708: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "[2023-03-16 14:30:00,853] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
            "\u001b[38;5;4mℹ Saving to output directory: model\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-03-16 14:30:01,087] [INFO] Set up nlp object from config\n",
            "[2023-03-16 14:30:01,093] [DEBUG] Loading corpus from path: dev.spacy\n",
            "[2023-03-16 14:30:01,094] [DEBUG] Loading corpus from path: train.spacy\n",
            "[2023-03-16 14:30:01,094] [INFO] Pipeline: ['textcat']\n",
            "[2023-03-16 14:30:01,096] [INFO] Created vocabulary\n",
            "[2023-03-16 14:30:01,096] [INFO] Finished initializing nlp object\n",
            "[2023-03-16 14:30:26,723] [INFO] Initialized pipeline components: ['textcat']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "[2023-03-16 14:30:26,730] [DEBUG] Loading corpus from path: dev.spacy\n",
            "[2023-03-16 14:30:26,731] [DEBUG] Loading corpus from path: train.spacy\n",
            "[2023-03-16 14:30:26,732] [DEBUG] Removed existing output directory: model/model-best\n",
            "[2023-03-16 14:30:26,732] [DEBUG] Removed existing output directory: model/model-last\n",
            "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
            "---  ------  ------------  ----------  ------\n",
            "  0       0          0.25       36.86    0.37\n",
            "  0     200         44.07       75.92    0.76\n",
            "  0     400         33.59       78.67    0.79\n",
            "  0     600         31.25       80.69    0.81\n",
            "  0     800         27.25       82.11    0.82\n",
            "  0    1000         26.53       83.05    0.83\n",
            "  0    1200         23.67       83.24    0.83\n",
            "  0    1400         23.69       84.35    0.84\n",
            "  0    1600         23.70       84.64    0.85\n",
            "  0    1800         22.72       85.12    0.85\n",
            "  0    2000         21.17       85.41    0.85\n",
            "  0    2200         20.97       85.83    0.86\n",
            "  0    2400         19.99       86.06    0.86\n",
            "  0    2600         19.30       86.33    0.86\n",
            "  0    2800         19.97       86.52    0.87\n",
            "  0    3000         19.76       86.66    0.87\n",
            "  0    3200         18.46       86.81    0.87\n",
            "  0    3400         18.84       86.89    0.87\n",
            "  0    3600         19.36       87.04    0.87\n",
            "  0    3800         17.53       87.23    0.87\n",
            "  0    4000         18.80       87.07    0.87\n",
            "  1    4200         14.22       87.04    0.87\n",
            "  1    4400         11.89       87.03    0.87\n",
            "  1    4600         12.85       87.06    0.87\n",
            "  1    4800         12.34       87.09    0.87\n",
            "  1    5000         13.47       87.00    0.87\n",
            "  1    5200         13.05       86.93    0.87\n",
            "  1    5400         13.12       86.83    0.87\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model/model-last\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy --output model --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu86WE1s7U-U",
        "outputId": "1a34a7d8-c29d-4718-ca93-e9af79f9e26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-16 14:34:21.918688: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-03-16 14:34:22.434323: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:22.434376: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:22.434383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-16 14:34:23.339304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:23.339359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:23.340847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:23.340889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:23.340918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2023-03-16 14:34:23.340926: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK                 100.00\n",
            "TEXTCAT (macro F)   87.56 \n",
            "SPEED               521044\n",
            "\n",
            "\u001b[1m\n",
            "=========================== Textcat F (per label) ===========================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "POS   87.20   88.07   87.63\n",
            "NEG   87.93   87.05   87.48\n",
            "\n",
            "\u001b[1m\n",
            "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
            "\n",
            "      ROC AUC\n",
            "POS      0.94\n",
            "NEG      0.94\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy evaluate ./model/model-best/ ./test.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIL78FGo7U-U",
        "outputId": "120b2bc5-9847-423b-9056-02191b1787a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'POS': 0.08944917470216751, 'NEG': 0.9105508327484131} - This movie is unnecessarily long. At times it gets boring and hard to follow.\n",
            "{'POS': 0.3397209644317627, 'NEG': 0.6602790355682373} - I regretted ever purchasing or making order on this platform.\n"
          ]
        }
      ],
      "source": [
        "texts = [\"This movie is unnecessarily long. At times it gets boring and hard to follow.\", \"I regretted ever purchasing or making order on this platform.\"]\n",
        "nlp = spacy.load(\"./model/model-best\")\n",
        "for text in texts:\n",
        "    doc = nlp(preprocessing(text))\n",
        "    print(doc.cats,  \"-\",  text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XXeIKu77U-U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3800 Tópicos en CC - NLP UC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versiones de librerías, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- nltk 3.7\n",
    "- lime 0.2.0.1\n",
    "- spacy 3.5.1\n",
    "- gcsfs 2023.3.0\n",
    "- protobuf 3.20.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m product_reviews_1\n\u001b[0;32m      2\u001b[0m camera_reviews \u001b[39m=\u001b[39m product_reviews_1\u001b[39m.\u001b[39mreviews(\u001b[39m'\u001b[39m\u001b[39mCanon_G3.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m reviews \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import product_reviews_1\n",
    "camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for review in camera_reviews:\n",
    "    sentences = []\n",
    "    for sentence in review.sents():\n",
    "        text = \" \".join(sentence)\n",
    "        sentences.append(text)\n",
    "    document = \" \".join(sentences)\n",
    "    reviews.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize tokenizer\n",
    "# It's also possible to try with a stemmer or to mix a stemmer and a lemmatizer\n",
    "tokenizer = RegexpTokenizer('[\\'a-zA-Z]+')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(document):\n",
    "    words = []\n",
    "\n",
    "    for sentence in sent_tokenize(document):\n",
    "        tokens = [lemmatizer.lemmatize(t.lower()) for t in tokenizer.tokenize(sentence) if t.lower() not in stop_words and len(t) > 2]\n",
    "        words += tokens\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for review in reviews:\n",
    "    document = tokenize(review)\n",
    "    corpus.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer() # compound in [-1,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver documentación de vader en: https://www.nltk.org/api/nltk.sentiment.vader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(len(corpus)):\n",
    "    if analyzer.polarity_scores(corpus[i])['compound'] > 0.2: \n",
    "        label.append('Positive') # positive sentiment\n",
    "    elif analyzer.polarity_scores(corpus[i])['compound'] < -0.2:\n",
    "        label.append('Negative') # negative sentiment\n",
    "    else:\n",
    "        label.append('Neutral') # neutral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(corpus, columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpolarities\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m label\n\u001b[0;32m      5\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(corpus, columns = ['review'])\n",
    "df['polarities'] = label\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised sentiment analysis (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas.lagos\\AppData\\Local\\Temp\\ipykernel_16724\\2090278574.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('gs://nlp_amazon_data/train.ft.txt', sep=\"__label__\", header = None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load in dataset and separate by the __label__ classifier in the text file\n",
    "data = pd.read_csv('gs://nlp_amazon_data/train.ft.txt', sep=\"__label__\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599995</th>\n",
       "      <td>Don't do it!!: The high chair looks great when...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599996</th>\n",
       "      <td>Looks nice, low functionality: I have used thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599997</th>\n",
       "      <td>compact, but hard to clean: We have a small ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599998</th>\n",
       "      <td>what is it saying?: not sure what this book is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599999</th>\n",
       "      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review sentiment\n",
       "0        Stuning even for the non-gamer: This sound tra...         2\n",
       "1        The best soundtrack ever to anything.: I'm rea...         2\n",
       "2        Amazing!: This soundtrack is my favorite music...         2\n",
       "3        Excellent Soundtrack: I truly like this soundt...         2\n",
       "4        Remember, Pull Your Jaw Off The Floor After He...         2\n",
       "...                                                    ...       ...\n",
       "3599995  Don't do it!!: The high chair looks great when...         1\n",
       "3599996  Looks nice, low functionality: I have used thi...         1\n",
       "3599997  compact, but hard to clean: We have a small ho...         1\n",
       "3599998  what is it saying?: not sure what this book is...         1\n",
       "3599999  Makes My Blood Run Red-White-And-Blue: I agree...         2\n",
       "\n",
       "[3600000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(0, inplace=True, axis=1)\n",
    "data['sentiment'] = data[1].str[0]\n",
    "data[1] = data[1].str[2:]\n",
    "data = data.rename(columns={1: 'review'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(n=100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1669564</th>\n",
       "      <td>Awesome!: These are Great! Bought these for my...</td>\n",
       "      <td>2</td>\n",
       "      <td>awesome great bought daughter boyfriend loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314648</th>\n",
       "      <td>Shame on you Lewin!: Corrupting the integrity ...</td>\n",
       "      <td>1</td>\n",
       "      <td>shame lewin corrupting integrity amazon review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226503</th>\n",
       "      <td>ultimate christmas c d volumn 3: here we go ag...</td>\n",
       "      <td>2</td>\n",
       "      <td>ultimate christmas volumn great christmas favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709998</th>\n",
       "      <td>Stand has a major defect: I bought this monito...</td>\n",
       "      <td>1</td>\n",
       "      <td>stand major defect bought monitor months ago s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360808</th>\n",
       "      <td>Track After Track, On Repeat, Delicious to the...</td>\n",
       "      <td>2</td>\n",
       "      <td>track track repeat delicious ears feet lies li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review sentiment  \\\n",
       "1669564  Awesome!: These are Great! Bought these for my...         2   \n",
       "3314648  Shame on you Lewin!: Corrupting the integrity ...         1   \n",
       "1226503  ultimate christmas c d volumn 3: here we go ag...         2   \n",
       "709998   Stand has a major defect: I bought this monito...         1   \n",
       "360808   Track After Track, On Repeat, Delicious to the...         2   \n",
       "\n",
       "                                                text_clean  \n",
       "1669564  awesome great bought daughter boyfriend loves ...  \n",
       "3314648  shame lewin corrupting integrity amazon review...  \n",
       "1226503  ultimate christmas volumn great christmas favo...  \n",
       "709998   stand major defect bought monitor months ago s...  \n",
       "360808   track track repeat delicious ears feet lies li...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.blank(\"es\") # Create a blank pipeline of a given language class\n",
    "REGX_USERNAME = r\"@[A-Za-z0-9$-_@.&+]+\"\n",
    "\n",
    "def preprocessing(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(REGX_USERNAME, ' ', text)\n",
    "  tokens = [token.text for token in nlp(text)]\n",
    "  tokens = [t for t in tokens if t not in STOP_WORDS and t not in string.punctuation and len(t) > 2]\n",
    "  tokens = [t for t in tokens if not t.isdigit()]\n",
    "\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "sample[\"text_clean\"] = sample[\"review\"].apply(preprocessing)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1669564</th>\n",
       "      <td>Awesome!: These are Great! Bought these for my...</td>\n",
       "      <td>2</td>\n",
       "      <td>awesome great bought daughter boyfriend loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314648</th>\n",
       "      <td>Shame on you Lewin!: Corrupting the integrity ...</td>\n",
       "      <td>1</td>\n",
       "      <td>shame lewin corrupting integrity amazon review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226503</th>\n",
       "      <td>ultimate christmas c d volumn 3: here we go ag...</td>\n",
       "      <td>2</td>\n",
       "      <td>ultimate christmas volumn great christmas favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709998</th>\n",
       "      <td>Stand has a major defect: I bought this monito...</td>\n",
       "      <td>1</td>\n",
       "      <td>stand major defect bought monitor months ago s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360808</th>\n",
       "      <td>Track After Track, On Repeat, Delicious to the...</td>\n",
       "      <td>2</td>\n",
       "      <td>track track repeat delicious ears feet lies li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765260</th>\n",
       "      <td>Not Recommended: Many of the recipes in this b...</td>\n",
       "      <td>1</td>\n",
       "      <td>recommended recipes book include ingredients b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508426</th>\n",
       "      <td>Their Greatest!: This is George Michael/Wham's...</td>\n",
       "      <td>2</td>\n",
       "      <td>greatest george michael wham greatest album tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098618</th>\n",
       "      <td>Cadburys Flake Case of 24: Very good product. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>cadburys flake case good product family loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203438</th>\n",
       "      <td>Can server the purpose: I bought two of these ...</td>\n",
       "      <td>1</td>\n",
       "      <td>server purpose bought items small work suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794850</th>\n",
       "      <td>HORRIBLE, AWFUL, DISAPPOINTING, RIDICULOUS!: T...</td>\n",
       "      <td>1</td>\n",
       "      <td>horrible awful disappointing ridiculous prosal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review sentiment  \\\n",
       "1669564  Awesome!: These are Great! Bought these for my...         2   \n",
       "3314648  Shame on you Lewin!: Corrupting the integrity ...         1   \n",
       "1226503  ultimate christmas c d volumn 3: here we go ag...         2   \n",
       "709998   Stand has a major defect: I bought this monito...         1   \n",
       "360808   Track After Track, On Repeat, Delicious to the...         2   \n",
       "...                                                    ...       ...   \n",
       "1765260  Not Recommended: Many of the recipes in this b...         1   \n",
       "2508426  Their Greatest!: This is George Michael/Wham's...         2   \n",
       "3098618  Cadburys Flake Case of 24: Very good product. ...         2   \n",
       "1203438  Can server the purpose: I bought two of these ...         1   \n",
       "1794850  HORRIBLE, AWFUL, DISAPPOINTING, RIDICULOUS!: T...         1   \n",
       "\n",
       "                                                text_clean  \n",
       "1669564  awesome great bought daughter boyfriend loves ...  \n",
       "3314648  shame lewin corrupting integrity amazon review...  \n",
       "1226503  ultimate christmas volumn great christmas favo...  \n",
       "709998   stand major defect bought monitor months ago s...  \n",
       "360808   track track repeat delicious ears feet lies li...  \n",
       "...                                                    ...  \n",
       "1765260  recommended recipes book include ingredients b...  \n",
       "2508426  greatest george michael wham greatest album tr...  \n",
       "3098618  cadburys flake case good product family loves ...  \n",
       "1203438  server purpose bought items small work suggest...  \n",
       "1794850  horrible awful disappointing ridiculous prosal...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(sample[[\"text_clean\", \"sentiment\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "train_data = dataset[:75000]  # 75%\n",
    "dev_data = dataset[75000:90000] # 15%\n",
    "test_data = dataset[90000:] # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data, outfile):\n",
    "    db = spacy.tokens.DocBin()\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        doc.cats[\"POS\"] = label == '2'\n",
    "        doc.cats[\"NEG\"] = label == '1'\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(outfile)\n",
    "convert(train_data, \"./train.spacy\")\n",
    "convert(dev_data, \"./dev.spacy\")\n",
    "convert(test_data, \"./test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 14:29:55.174794: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-16 14:29:55.690500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:55.690563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:55.690573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16 14:29:56.644307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:56.644367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:56.645865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:56.645923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:56.645960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:56.645968: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init config --lang en --pipeline textcat --optimize efficiency --force config.cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver documentación de config en: https://spacy.io/usage/training#quickstart\n",
    "\n",
    "Ver documentación de architectures en: https://spacy.io/api/architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 14:29:59.199420: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-16 14:29:59.711462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:59.711518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:29:59.711524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16 14:30:00.632075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:30:00.632133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:30:00.633629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:30:00.633671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:30:00.633701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:30:00.633708: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[2023-03-16 14:30:00,853] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;4mℹ Saving to output directory: model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-16 14:30:01,087] [INFO] Set up nlp object from config\n",
      "[2023-03-16 14:30:01,093] [DEBUG] Loading corpus from path: dev.spacy\n",
      "[2023-03-16 14:30:01,094] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2023-03-16 14:30:01,094] [INFO] Pipeline: ['textcat']\n",
      "[2023-03-16 14:30:01,096] [INFO] Created vocabulary\n",
      "[2023-03-16 14:30:01,096] [INFO] Finished initializing nlp object\n",
      "[2023-03-16 14:30:26,723] [INFO] Initialized pipeline components: ['textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2023-03-16 14:30:26,730] [DEBUG] Loading corpus from path: dev.spacy\n",
      "[2023-03-16 14:30:26,731] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2023-03-16 14:30:26,732] [DEBUG] Removed existing output directory: model/model-best\n",
      "[2023-03-16 14:30:26,732] [DEBUG] Removed existing output directory: model/model-last\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.25       36.86    0.37\n",
      "  0     200         44.07       75.92    0.76\n",
      "  0     400         33.59       78.67    0.79\n",
      "  0     600         31.25       80.69    0.81\n",
      "  0     800         27.25       82.11    0.82\n",
      "  0    1000         26.53       83.05    0.83\n",
      "  0    1200         23.67       83.24    0.83\n",
      "  0    1400         23.69       84.35    0.84\n",
      "  0    1600         23.70       84.64    0.85\n",
      "  0    1800         22.72       85.12    0.85\n",
      "  0    2000         21.17       85.41    0.85\n",
      "  0    2200         20.97       85.83    0.86\n",
      "  0    2400         19.99       86.06    0.86\n",
      "  0    2600         19.30       86.33    0.86\n",
      "  0    2800         19.97       86.52    0.87\n",
      "  0    3000         19.76       86.66    0.87\n",
      "  0    3200         18.46       86.81    0.87\n",
      "  0    3400         18.84       86.89    0.87\n",
      "  0    3600         19.36       87.04    0.87\n",
      "  0    3800         17.53       87.23    0.87\n",
      "  0    4000         18.80       87.07    0.87\n",
      "  1    4200         14.22       87.04    0.87\n",
      "  1    4400         11.89       87.03    0.87\n",
      "  1    4600         12.85       87.06    0.87\n",
      "  1    4800         12.34       87.09    0.87\n",
      "  1    5000         13.47       87.00    0.87\n",
      "  1    5200         13.05       86.93    0.87\n",
      "  1    5400         13.12       86.83    0.87\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy --output model --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 14:34:21.918688: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-16 14:34:22.434323: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:22.434376: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:22.434383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16 14:34:23.339304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:23.339359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:23.340847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:23.340889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:23.340918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-16 14:34:23.340926: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   87.56 \n",
      "SPEED               521044\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "          P       R       F\n",
      "POS   87.20   88.07   87.63\n",
      "NEG   87.93   87.05   87.48\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "      ROC AUC\n",
      "POS      0.94\n",
      "NEG      0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy evaluate ./model/model-best/ ./test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POS': 0.08944917470216751, 'NEG': 0.9105508327484131} - This movie is unnecessarily long. At times it gets boring and hard to follow.\n",
      "{'POS': 0.3397209644317627, 'NEG': 0.6602790355682373} - I regretted ever purchasing or making order on this platform.\n"
     ]
    }
   ],
   "source": [
    "texts = [\"This movie is unnecessarily long. At times it gets boring and hard to follow.\", \"I regretted ever purchasing or making order on this platform.\"]\n",
    "nlp = spacy.load(\"./model/model-best\")\n",
    "for text in texts:\n",
    "    doc = nlp(preprocessing(text))\n",
    "    print(doc.cats,  \"-\",  text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
